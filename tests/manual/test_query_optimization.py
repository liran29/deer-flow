#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æŸ¥è¯¢ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•

æµ‹è¯•database researchç³»ç»Ÿçš„æŸ¥è¯¢ä¼˜åŒ–åŠŸèƒ½ï¼ŒéªŒè¯ï¼š
1. Plannerèƒ½å¤Ÿç”Ÿæˆæ™ºèƒ½çš„æŸ¥è¯¢ç­–ç•¥
2. Researcherèƒ½å¤Ÿæ ¹æ®ç­–ç•¥æ‰§è¡Œä¼˜åŒ–çš„æŸ¥è¯¢
3. æ•´ä½“å·¥ä½œæµçš„æ•ˆç‡æ”¹è¿›
"""

import asyncio
import logging
from src.graph.types import State
from src.graph.nodes_database import (
    database_investigation_node, 
    database_planner_node,
    database_researcher_node,
    _get_strategy_guidance,
    _analyze_execution_result
)
from src.prompts.planner_model import QueryStrategy, ResultSize
from langgraph.types import RunnableConfig

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_query_optimization_workflow():
    """æµ‹è¯•å®Œæ•´çš„æŸ¥è¯¢ä¼˜åŒ–å·¥ä½œæµ"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•æŸ¥è¯¢ä¼˜åŒ–å·¥ä½œæµ...")
    
    # æµ‹è¯•ç”¨ä¾‹ï¼šç”¨æˆ·æŸ¥è¯¢å¤§æ•°æ®é‡çš„å…¸å‹åœºæ™¯
    test_cases = [
        {
            "name": "è®¢å•å…¨é‡åˆ†æ",
            "query": "åˆ†æ2024å¹´æ²ƒå°”ç›æ‰€æœ‰è®¢å•æ•°æ®ï¼ŒåŒ…æ‹¬é”€å”®è¶‹åŠ¿ã€ç±»åˆ«åˆ†å¸ƒå’Œå¼‚å¸¸è®¢å•",
            "expected_strategies": ["aggregation", "aggregation", "sampling"]
        },
        {
            "name": "å•†å“æ€§èƒ½åˆ†æ", 
            "query": "æŸ¥çœ‹æ‰€æœ‰å•†å“çš„é”€å”®è¡¨ç°ï¼Œæ‰¾å‡ºçƒ­é”€å’Œæ»é”€å•†å“",
            "expected_strategies": ["aggregation", "window_analysis"]
        }
    ]
    
    for case in test_cases:
        print(f"\nğŸ“Š æµ‹è¯•æ¡ˆä¾‹: {case['name']}")
        await test_single_case(case['query'], case['expected_strategies'])
    
    print("\nâœ… æŸ¥è¯¢ä¼˜åŒ–å·¥ä½œæµæµ‹è¯•å®Œæˆï¼")


async def test_single_case(user_query: str, expected_strategies: list):
    """æµ‹è¯•å•ä¸ªæŸ¥è¯¢æ¡ˆä¾‹"""
    # åˆå§‹åŒ–çŠ¶æ€
    state = State(
        messages=[],
        research_topic=user_query,
        locale='zh-CN',
        enable_background_investigation=True
    )
    
    config = RunnableConfig()
    
    try:
        # 1. Investigationé˜¶æ®µ
        print("  ğŸ” æ‰§è¡Œæ•°æ®åº“è°ƒæŸ¥...")
        investigation_result = await database_investigation_node(state, config)
        # æ£€æŸ¥è¿”å›ç»“æœå¹¶æ›´æ–°state
        if isinstance(investigation_result, dict) and 'database_investigation_results' in investigation_result:
            state['database_investigation_results'] = investigation_result['database_investigation_results']
        
        # 2. Planningé˜¶æ®µ  
        print("  ğŸ“‹ ç”ŸæˆæŸ¥è¯¢ä¼˜åŒ–è®¡åˆ’...")
        planning_result = database_planner_node(state, config)
        plan = planning_result.update['current_plan']
        
        print(f"     è®¡åˆ’æ ‡é¢˜: {plan.title}")
        print(f"     æ­¥éª¤æ•°é‡: {len(plan.steps)}")
        
        # éªŒè¯æŸ¥è¯¢ç­–ç•¥
        actual_strategies = [step.query_strategy.value for step in plan.steps]
        print(f"     å®é™…ç­–ç•¥: {actual_strategies}")
        print(f"     æœŸæœ›ç­–ç•¥: {expected_strategies}")
        
        # æ£€æŸ¥ç­–ç•¥æ˜¯å¦åˆç†
        aggregation_count = actual_strategies.count('aggregation')
        total_steps = len(actual_strategies)
        aggregation_ratio = aggregation_count / total_steps
        
        print(f"     èšåˆç­–ç•¥å æ¯”: {aggregation_ratio:.1%} (ç›®æ ‡: >70%)")
        
        if aggregation_ratio >= 0.7:
            print("     âœ… æŸ¥è¯¢ç­–ç•¥åˆ†å¸ƒåˆç†")
        else:
            print("     âš ï¸  èšåˆç­–ç•¥å æ¯”åä½")
        
        # 3. æµ‹è¯•ç­–ç•¥æŒ‡å¯¼ç”Ÿæˆ
        print("  ğŸ“ æµ‹è¯•ç­–ç•¥æŒ‡å¯¼...")
        for i, step in enumerate(plan.steps):
            guidance = _get_strategy_guidance(step)
            print(f"     æ­¥éª¤{i+1} ({step.query_strategy.value}): æŒ‡å¯¼é•¿åº¦ {len(guidance)} å­—ç¬¦")
            
            # éªŒè¯å…³é”®æŒ‡å¯¼å†…å®¹
            if step.query_strategy == QueryStrategy.AGGREGATION:
                assert "èšåˆå‡½æ•°" in guidance
                assert "GROUP BY" in guidance
            elif step.query_strategy == QueryStrategy.SAMPLING:
                assert "LIMIT" in guidance
                assert str(step.batch_size or 20) in guidance
        
        print("     âœ… ç­–ç•¥æŒ‡å¯¼ç”Ÿæˆæ­£ç¡®")
        
        # 4. æ¨¡æ‹Ÿæ‰§è¡Œç»“æœåˆ†æ
        print("  ğŸ¯ æµ‹è¯•æ‰§è¡Œæ•ˆç‡åˆ†æ...")
        
        # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„æ‰§è¡Œç»“æœ
        test_results = [
            ("èšåˆæŸ¥è¯¢ç»“æœ", "æŸ¥è¯¢è¿”å›äº†3è¡Œç»Ÿè®¡æ•°æ®ï¼šæ€»è®¢å•æ•°10000ï¼Œæ€»é‡‘é¢500ä¸‡ï¼Œå¹³å‡é‡‘é¢500å…ƒ"),
            ("å¤§æ•°æ®é‡ç»“æœ", "æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼ŒRetrieved 2000 rows from walmart_orders table"),
            ("é‡‡æ ·ç»“æœ", "æŸ¥è¯¢è¿”å›äº†15ä¸ªé«˜ä»·å€¼è®¢å•æ ·ä¾‹ï¼Œç”¨äºå¼‚å¸¸åˆ†æ")
        ]
        
        for result_name, result_content in test_results:
            analysis = _analyze_execution_result(plan.steps[0], result_content)
            print(f"     {result_name}: æ•ˆç‡ {'âœ…' if analysis['is_efficient'] else 'âš ï¸'}ï¼Œæ•°æ®é‡ {analysis['data_volume_estimate']}")
        
        print("     âœ… æ‰§è¡Œæ•ˆç‡åˆ†ææ­£ç¡®")
        
    except Exception as e:
        print(f"     âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise


async def test_strategy_guidance_generation():
    """æµ‹è¯•ç­–ç•¥æŒ‡å¯¼ç”ŸæˆåŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•ç­–ç•¥æŒ‡å¯¼ç”Ÿæˆ...")
    
    from src.prompts.planner_model import Step
    
    # åˆ›å»ºä¸åŒç­–ç•¥çš„æµ‹è¯•æ­¥éª¤
    test_steps = [
        Step(
            need_search=False,
            title="èšåˆæµ‹è¯•",
            description="æµ‹è¯•èšåˆç­–ç•¥",
            step_type="processing",
            query_strategy=QueryStrategy.AGGREGATION,
            justification="ç»Ÿè®¡åˆ†æ",
            expected_result_size=ResultSize.SMALL_SET
        ),
        Step(
            need_search=False,
            title="é‡‡æ ·æµ‹è¯•", 
            description="æµ‹è¯•é‡‡æ ·ç­–ç•¥",
            step_type="processing",
            query_strategy=QueryStrategy.SAMPLING,
            batch_size=30,
            justification="éœ€è¦æ ·æœ¬æ•°æ®",
            expected_result_size=ResultSize.SMALL_SET
        ),
        Step(
            need_search=False,
            title="åˆ†é¡µæµ‹è¯•",
            description="æµ‹è¯•åˆ†é¡µç­–ç•¥", 
            step_type="processing",
            query_strategy=QueryStrategy.PAGINATION,
            batch_size=1000,
            max_batches=5,
            justification="å¤§æ•°æ®å¤„ç†",
            expected_result_size=ResultSize.MEDIUM_SET
        )
    ]
    
    for step in test_steps:
        guidance = _get_strategy_guidance(step)
        print(f"  ğŸ“ {step.query_strategy.value} ç­–ç•¥æŒ‡å¯¼:")
        print(f"     é•¿åº¦: {len(guidance)} å­—ç¬¦")
        print(f"     åŒ…å«ç­–ç•¥å: {'âœ…' if step.query_strategy.value in guidance else 'âŒ'}")
        print(f"     åŒ…å«ç†ç”±: {'âœ…' if step.justification in guidance else 'âŒ'}")
        
        # éªŒè¯ç­–ç•¥ç‰¹å®šå†…å®¹
        if step.query_strategy == QueryStrategy.AGGREGATION:
            assert "COUNT()" in guidance and "GROUP BY" in guidance
        elif step.query_strategy == QueryStrategy.SAMPLING:
            assert f"LIMIT {step.batch_size}" in guidance
        elif step.query_strategy == QueryStrategy.PAGINATION:
            assert f"LIMIT {step.batch_size}" in guidance
            assert "åˆ†æ‰¹" in guidance
    
    print("  âœ… ç­–ç•¥æŒ‡å¯¼ç”Ÿæˆæµ‹è¯•é€šè¿‡")


async def test_efficiency_analysis():
    """æµ‹è¯•æ‰§è¡Œæ•ˆç‡åˆ†æåŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•æ‰§è¡Œæ•ˆç‡åˆ†æ...")
    
    from src.prompts.planner_model import Step
    
    test_step = Step(
        need_search=False,
        title="æµ‹è¯•æ­¥éª¤",
        description="æµ‹è¯•",
        step_type="processing",  
        query_strategy=QueryStrategy.AGGREGATION,
        justification="æµ‹è¯•",
        expected_result_size=ResultSize.SMALL_SET
    )
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„æ‰§è¡Œç»“æœ
    test_cases = [
        {
            "name": "é«˜æ•ˆèšåˆæŸ¥è¯¢",
            "result": "ç»Ÿè®¡åˆ†æå®Œæˆï¼šæ€»è®¢å•3000ç¬”ï¼Œå¹³å‡é‡‘é¢450å…ƒï¼Œä¸»è¦ç±»åˆ«5ä¸ª",
            "should_be_efficient": True
        },
        {
            "name": "å¤§æ•°æ®é‡æŸ¥è¯¢",
            "result": "æŸ¥è¯¢å®Œæˆï¼ŒRetrieved 1500 rows from database",
            "should_be_efficient": False
        },
        {
            "name": "æ­£å¸¸é™åˆ¶æŸ¥è¯¢",
            "result": "æŸ¥è¯¢è¿”å›50è¡Œæ•°æ®ï¼ŒLIMIT 50åº”ç”¨æˆåŠŸ",
            "should_be_efficient": True
        }
    ]
    
    for case in test_cases:
        analysis = _analyze_execution_result(test_step, case["result"])
        actual_efficient = analysis["is_efficient"]
        expected_efficient = case["should_be_efficient"]
        
        print(f"  ğŸ“Š {case['name']}:")
        print(f"     æ•ˆç‡åˆ¤æ–­: {'âœ…' if actual_efficient == expected_efficient else 'âŒ'}")
        print(f"     æ•°æ®é‡ä¼°è®¡: {analysis['data_volume_estimate']}")
        if analysis["warnings"]:
            print(f"     è­¦å‘Š: {analysis['warnings']}")
        if analysis["suggestions"]:
            print(f"     å»ºè®®: {analysis['suggestions']}")
    
    print("  âœ… æ‰§è¡Œæ•ˆç‡åˆ†ææµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    async def main():
        await test_query_optimization_workflow()
        await test_strategy_guidance_generation()
        await test_efficiency_analysis()
        
        print("\nğŸ‰ æ‰€æœ‰æŸ¥è¯¢ä¼˜åŒ–æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")
        print("\nä¸»è¦æ”¹è¿›ï¼š")
        print("1. âœ… Planneræ™ºèƒ½ç”ŸæˆæŸ¥è¯¢ç­–ç•¥ï¼ˆ70%+èšåˆç­–ç•¥ï¼‰")
        print("2. âœ… Researcheræ ¹æ®ç­–ç•¥æ‰§è¡Œä¼˜åŒ–æŸ¥è¯¢")
        print("3. âœ… å®æ—¶ç›‘æ§å’Œæ•ˆç‡åˆ†æ")
        print("4. âœ… å‡å°‘å¤§æ•°æ®é‡æŸ¥è¯¢ï¼Œæå‡æ€§èƒ½")
    
    asyncio.run(main())