#!/usr/bin/env python3
"""
è¯Šæ–­è„šæœ¬ - åˆ†ææ½œåœ¨é—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆ
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

import asyncio
import logging
from src.utils.token_manager import TokenManager
from src.config import load_yaml_config
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def diagnose_config():
    """è¯Šæ–­é…ç½®ç›¸å…³é—®é¢˜"""
    print("\n" + "="*80)
    print("ğŸ” é…ç½®è¯Šæ–­")
    print("="*80)
    
    try:
        token_manager = TokenManager()
        print(f"âœ… TokenManager åˆå§‹åŒ–æˆåŠŸ")
        print(f"ğŸ“„ é…ç½®æ–‡ä»¶è·¯å¾„: {token_manager.config_path}")
        
        config_data = load_yaml_config(token_manager.config_path)
        print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        # Check basic model config
        basic_model = config_data.get("BASIC_MODEL", {})
        if basic_model:
            print(f"ğŸ¤– åŸºç¡€æ¨¡å‹: {basic_model.get('model', 'N/A')}")
            print(f"ğŸ”— APIåœ°å€: {basic_model.get('base_url', 'N/A')}")
        else:
            print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ° BASIC_MODEL é…ç½®")
        
        # Check token management config
        token_config = config_data.get("TOKEN_MANAGEMENT", {})
        if token_config:
            print(f"ğŸ›¡ï¸  Tokenç®¡ç†: {'å¯ç”¨' if token_config.get('enabled') else 'ç¦ç”¨'}")
            strategies = token_config.get("trimming_strategies", {})
            print(f"ğŸ“ é…ç½®çš„èŠ‚ç‚¹: {list(strategies.keys())}")
        else:
            print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ° TOKEN_MANAGEMENT é…ç½®")
            
    except Exception as e:
        print(f"âŒ é…ç½®è¯Šæ–­å¤±è´¥: {e}")

def diagnose_token_management():
    """è¯Šæ–­ Token ç®¡ç†åŠŸèƒ½"""
    print("\n" + "="*80)
    print("ğŸ” Token ç®¡ç†è¯Šæ–­")
    print("="*80)
    
    try:
        token_manager = TokenManager()
        
        # Test with large message set
        print("\nğŸ“Š æµ‹è¯•å¤§é‡æ¶ˆæ¯çš„ token ç®¡ç†...")
        large_messages = [SystemMessage(content="You are a helpful assistant.")]
        
        # Create messages that will definitely exceed limits
        for i in range(100):
            large_messages.append(HumanMessage(
                content=f"Question {i}: " + "This is a very long question " * 100
            ))
            large_messages.append(AIMessage(
                content=f"Answer {i}: " + "This is a very detailed answer " * 150
            ))
        
        print(f"ğŸ“ ç”Ÿæˆæ¶ˆæ¯æ•°: {len(large_messages)}")
        
        # Test each node type
        test_nodes = ["planner", "reporter", "researcher", "background_investigation"]
        
        for node in test_nodes:
            print(f"\nğŸ” æµ‹è¯•èŠ‚ç‚¹: {node}")
            try:
                result = token_manager.trim_messages_for_node(
                    large_messages, "deepseek-chat", node
                )
                print(f"   ç»“æœ: {len(large_messages)} â†’ {len(result)} æ¶ˆæ¯")
            except Exception as e:
                print(f"   âŒ é”™è¯¯: {e}")
                
    except Exception as e:
        print(f"âŒ Token ç®¡ç†è¯Šæ–­å¤±è´¥: {e}")

def diagnose_import_issues():
    """è¯Šæ–­å¯¼å…¥ç›¸å…³é—®é¢˜"""
    print("\n" + "="*80)
    print("ğŸ” å¯¼å…¥è¯Šæ–­")
    print("="*80)
    
    imports_to_test = [
        ("src.utils.token_manager", "TokenManager"),
        ("src.config", "load_yaml_config"),
        ("src.config.configuration", "Configuration"),
        ("langchain_core.messages", "HumanMessage"),
        ("langchain_core.messages", "AIMessage"),
        ("langchain_core.messages", "SystemMessage"),
    ]
    
    for module_name, class_name in imports_to_test:
        try:
            module = __import__(module_name, fromlist=[class_name])
            cls = getattr(module, class_name)
            print(f"âœ… {module_name}.{class_name}")
        except ImportError as e:
            print(f"âŒ {module_name}.{class_name}: {e}")
        except AttributeError as e:
            print(f"âš ï¸  {module_name}.{class_name}: {e}")

def diagnose_callback_issues():
    """è¯Šæ–­å›è°ƒç›¸å…³é—®é¢˜"""
    print("\n" + "="*80)
    print("ğŸ” å›è°ƒè¯Šæ–­")
    print("="*80)
    
    print("æ£€æŸ¥åˆ°çš„é—®é¢˜:")
    print("1. LangGraph å›è°ƒé”™è¯¯: 'NoneType' object is not callable")
    print("   - è¿™å¯èƒ½æ˜¯ LangGraph ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜")
    print("   - æˆ–è€…æŸä¸ªäº‹ä»¶å¤„ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
    
    print("\n2. AsyncIO å–æ¶ˆé”™è¯¯: CancelledError")
    print("   - é€šå¸¸ç”±å®¢æˆ·ç«¯æ–­å¼€è¿æ¥å¼•èµ·")
    print("   - éœ€è¦æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œè¶…æ—¶ç®¡ç†")
    
    print("\nå»ºè®®è§£å†³æ–¹æ¡ˆ:")
    print("- åœ¨ server/app.py ä¸­æ·»åŠ æ›´å¥½çš„å¼‚å¸¸å¤„ç†")
    print("- è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´")
    print("- æ·»åŠ è¿æ¥çŠ¶æ€æ£€æŸ¥")

def main():
    """ä¸»è¯Šæ–­å‡½æ•°"""
    print("\nğŸ¥ DeerFlow ç³»ç»Ÿè¯Šæ–­æŠ¥å‘Š")
    print("=" * 80)
    
    diagnose_config()
    diagnose_import_issues() 
    diagnose_token_management()
    diagnose_callback_issues()
    
    print("\n" + "="*80)
    print("ğŸ“‹ è¯Šæ–­æ€»ç»“")
    print("="*80)
    print("âœ… ä¸»è¦åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    print("âœ… Token ç®¡ç†ç³»ç»Ÿå·²éƒ¨ç½²")
    print("âš ï¸  å‘ç°ä¸€äº›éè‡´å‘½æ€§é—®é¢˜:")
    print("   - LangGraph å›è°ƒé”™è¯¯ (ä¸å½±å“ä¸»è¦åŠŸèƒ½)")
    print("   - è¿æ¥å–æ¶ˆå¤„ç†å¯ä»¥ä¼˜åŒ–")
    print("ğŸ’¡ å»ºè®®: ç»§ç»­æµ‹è¯•å¤æ‚åœºæ™¯ä»¥éªŒè¯ token ç®¡ç†æ•ˆæœ")
    print("="*80 + "\n")

if __name__ == "__main__":
    main()