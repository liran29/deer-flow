#!/usr/bin/env python3
"""
æµ‹è¯• Token æ‰©å±•åˆ†æåŠŸèƒ½
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from src.utils.token_manager import TokenManager
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
import logging

# Configure logging to see detailed analysis
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def create_test_scenarios():
    """åˆ›å»ºä¸åŒçš„æµ‹è¯•åœºæ™¯æ¥è§¦å‘ token æ‰©å±•"""
    
    scenarios = []
    
    # Scenario 1: Simple messages (baseline)
    scenarios.append({
        "name": "åŸºç¡€åœºæ™¯",
        "messages": [
            SystemMessage(content="You are helpful."),
            HumanMessage(content="Hi"),
            AIMessage(content="Hello!")
        ]
    })
    
    # Scenario 2: Messages with observations (like reporter node)
    scenarios.append({
        "name": "åŒ…å«è§‚å¯Ÿæ•°æ®",
        "messages": [
            SystemMessage(content="Generate report based on findings."),
            HumanMessage(content="Research findings:\n<finding>\nTensorFlow performance data...\n</finding>"),
            AIMessage(content="Based on the observations, here is the analysis...")
        ]
    })
    
    # Scenario 3: Messages with metadata
    messages_with_metadata = [
        SystemMessage(content="System prompt"),
        HumanMessage(content="Query with additional info")
    ]
    # Add metadata to simulate real workflow
    messages_with_metadata[1].additional_kwargs = {"source": "user", "timestamp": "2025-01-01"}
    messages_with_metadata[1].response_metadata = {"processing_time": 0.5}
    
    scenarios.append({
        "name": "åŒ…å«å…ƒæ•°æ®",
        "messages": messages_with_metadata
    })
    
    # Scenario 4: Structured content
    scenarios.append({
        "name": "ç»“æ„åŒ–å†…å®¹",
        "messages": [
            SystemMessage(content="Process structured data"),
            HumanMessage(content='{"task": "analysis", "data": {"frameworks": ["TensorFlow", "PyTorch", "JAX"]}}'),
            AIMessage(content="## Analysis Results\n\n**Key Findings:**\n- Framework comparison\n- Performance metrics")
        ]
    })
    
    return scenarios

def test_expansion_analysis():
    """æµ‹è¯•æ‰©å±•åˆ†æåŠŸèƒ½"""
    
    print("\n" + "="*80)
    print("ğŸ” Token æ‰©å±•åˆ†ææµ‹è¯•")
    print("="*80)
    
    token_manager = TokenManager()
    scenarios = create_test_scenarios()
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"\nğŸ“‹ æµ‹è¯•åœºæ™¯ {i}: {scenario['name']}")
        print("-" * 60)
        
        messages = scenario['messages']
        
        # Test with reporter node (which showed expansion in logs)
        try:
            result = token_manager.trim_messages_for_node(
                messages, "deepseek-chat", "reporter"
            )
            
            print(f"âœ… å¤„ç†å®Œæˆ: {len(messages)} â†’ {len(result)} æ¶ˆæ¯")
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

def simulate_reporter_expansion():
    """ä¸“é—¨æ¨¡æ‹Ÿ reporter èŠ‚ç‚¹çš„ token æ‰©å±•æƒ…å†µ"""
    
    print("\n" + "="*80)
    print("ğŸ¯ æ¨¡æ‹Ÿ Reporter èŠ‚ç‚¹æ‰©å±•åœºæ™¯")
    print("="*80)
    
    token_manager = TokenManager()
    
    # Create a scenario similar to what might cause expansion in reporter
    messages = [
        SystemMessage(content="Generate a comprehensive research report based on the collected findings."),
        HumanMessage(content="""
# Research Findings Summary

## Finding 1: Performance Benchmarks
TensorFlow shows superior performance in distributed training scenarios.

## Finding 2: Architecture Analysis  
PyTorch provides more flexible distributed training APIs.

## Finding 3: Ecosystem Comparison
JAX demonstrates excellent performance but has limited ecosystem.
        """),
        AIMessage(content="I'll analyze these findings to create a comprehensive report."),
        HumanMessage(content="Please include detailed performance metrics and recommendations."),
        AIMessage(content="Based on the research findings, I'll structure the report as follows..."),
        HumanMessage(content="Also compare the frameworks' ease of use and learning curves.")
    ]
    
    print(f"ğŸ“ è¾“å…¥æ¶ˆæ¯æ•°: {len(messages)}")
    print("ğŸ”„ æ‰§è¡Œ token ç®¡ç†...")
    
    # This should trigger detailed expansion analysis if it occurs
    result = token_manager.trim_messages_for_node(
        messages, "deepseek-chat", "reporter"
    )
    
    print(f"âœ… è¾“å‡ºæ¶ˆæ¯æ•°: {len(result)}")
    print("\nğŸ’¡ æ£€æŸ¥ä¸Šæ–¹æ—¥å¿—ä¸­çš„è¯¦ç»†åˆ†æä¿¡æ¯")

def main():
    """ä¸»å‡½æ•°"""
    print("\nğŸ§ª Token æ‰©å±•æ·±åº¦åˆ†æç³»ç»Ÿ")
    print("=" * 80)
    print("è¿™ä¸ªæµ‹è¯•å°†å¸®åŠ©æˆ‘ä»¬ç†è§£ä¸ºä»€ä¹ˆä¼šå‡ºç° token æ‰©å±•")
    print("æ–°å¢çš„åˆ†æåŠŸèƒ½å°†æä¾›è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯")
    
    test_expansion_analysis()
    simulate_reporter_expansion()
    
    print("\n" + "="*80)
    print("ğŸ“Š åˆ†ææ€»ç»“")
    print("="*80)
    print("âœ… æ–°å¢äº†è¯¦ç»†çš„ token æ‰©å±•åˆ†æåŠŸèƒ½")
    print("âœ… èƒ½å¤Ÿæ£€æµ‹å¤šç§å¯èƒ½çš„æ‰©å±•åŸå› :")
    print("   - æ¶ˆæ¯æ ¼å¼è½¬æ¢")
    print("   - å…ƒæ•°æ®æ·»åŠ ")
    print("   - ç»“æ„åŒ–æ•°æ®å¤„ç†")
    print("   - è§‚å¯Ÿæ•°æ®æ•´åˆ")
    print("   - Markdown æ ¼å¼åŒ–")
    print("ğŸ’¡ ä¸‹æ¬¡å‡ºç°æ‰©å±•æ—¶ï¼Œæ—¥å¿—å°†æä¾›è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯")
    print("="*80 + "\n")

if __name__ == "__main__":
    main()