#!/usr/bin/env python3
"""
è¯Šæ–­ Token è¶…é™é—®é¢˜
åˆ†æä¸ºä»€ä¹ˆ researcher èŠ‚ç‚¹ä¼šè¶…å‡º 120K tokens
"""

import json
from pathlib import Path
from src.utils.token_manager import TokenManager
from src.utils.token_counter import TokenCounterFactory
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
import asyncio

def analyze_token_issue():
    """åˆ†æ token è¶…é™é—®é¢˜"""
    print("ğŸ” è¯Šæ–­ Token è¶…é™é—®é¢˜")
    print("="*60)
    
    # 1. æ£€æŸ¥é…ç½®
    token_manager = TokenManager()
    config = token_manager.token_management
    
    print("\nğŸ“‹ å½“å‰é…ç½®:")
    print(f"- Token ç®¡ç†å¯ç”¨: {config.get('enabled', False)}")
    print(f"- DeepSeek æ¨¡å‹é™åˆ¶: {config.get('model_limits', {}).get('deepseek-chat', 'N/A')} tokens")
    print(f"- Researcher èŠ‚ç‚¹é…ç½®:")
    researcher_config = config.get('trimming_strategies', {}).get('researcher', {})
    print(f"  - æœ€å¤§ tokens: {researcher_config.get('max_tokens', 'N/A')}")
    print(f"  - ç­–ç•¥: {researcher_config.get('strategy', 'N/A')}")
    print(f"  - è¾“å‡ºé¢„ç•™: {researcher_config.get('reserve_for_output', 0)}")
    
    # 2. æ¨¡æ‹Ÿé—®é¢˜åœºæ™¯
    print("\nğŸ§ª æ¨¡æ‹Ÿé—®é¢˜åœºæ™¯:")
    
    # åˆ›å»ºå¤§é‡æ¶ˆæ¯æ¨¡æ‹Ÿå®é™…æƒ…å†µ
    messages = []
    
    # ç³»ç»Ÿæ¶ˆæ¯
    messages.append(SystemMessage(content="You are a helpful research assistant. " * 100))
    
    # ç”¨æˆ·æŸ¥è¯¢
    messages.append(HumanMessage(content="æ·±å…¥åˆ†æå¤§è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—ã€é‡‘èã€æ•™è‚²ä¸‰ä¸ªé¢†åŸŸçš„åº”ç”¨ç°çŠ¶ã€æŠ€æœ¯æŒ‘æˆ˜å’Œæœªæ¥å‘å±•è¶‹åŠ¿"))
    
    # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯å’Œå·¥å…·è°ƒç”¨ç»“æœ
    for i in range(50):  # 50è½®å¯¹è¯
        # å·¥å…·è°ƒç”¨ç»“æœï¼ˆæœç´¢ç»“æœé€šå¸¸å¾ˆé•¿ï¼‰
        tool_result = f"æœç´¢ç»“æœ {i+1}:\n" + "è¿™æ˜¯ä¸€ä¸ªéå¸¸é•¿çš„æœç´¢ç»“æœå†…å®¹ã€‚" * 500
        messages.append(AIMessage(content=f"è®©æˆ‘æœç´¢ä¸€ä¸‹ç›¸å…³ä¿¡æ¯..."))
        messages.append(HumanMessage(content=tool_result))
    
    # è®¡ç®—åŸå§‹ token æ•°
    counter = TokenCounterFactory.create_counter("deepseek-chat")
    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
    message_dicts = []
    for msg in messages:
        if isinstance(msg, SystemMessage):
            message_dicts.append({"role": "system", "content": msg.content})
        elif isinstance(msg, HumanMessage):
            message_dicts.append({"role": "user", "content": msg.content})
        elif isinstance(msg, AIMessage):
            message_dicts.append({"role": "assistant", "content": msg.content})
    original_tokens = counter.count_messages_tokens(message_dicts)
    
    print(f"- åŸå§‹æ¶ˆæ¯æ•°: {len(messages)}")
    print(f"- åŸå§‹ token æ•°: {original_tokens:,}")
    
    # 3. åº”ç”¨ token ç®¡ç†
    print("\nğŸ”§ åº”ç”¨ Token ç®¡ç†:")
    try:
        trimmed_messages = token_manager.trim_messages_for_node(
            messages, "deepseek-chat", "researcher"
        )
        
        # è®¡ç®—ä¿®å‰ªåçš„ token æ•°
        trimmed_dicts = []
        for msg in trimmed_messages:
            if isinstance(msg, SystemMessage):
                trimmed_dicts.append({"role": "system", "content": msg.content})
            elif isinstance(msg, HumanMessage):
                trimmed_dicts.append({"role": "user", "content": msg.content})
            elif isinstance(msg, AIMessage):
                trimmed_dicts.append({"role": "assistant", "content": msg.content})
        trimmed_tokens = counter.count_messages_tokens(trimmed_dicts)
        
        print(f"- ä¿®å‰ªåæ¶ˆæ¯æ•°: {len(trimmed_messages)}")
        print(f"- ä¿®å‰ªå token æ•°: {trimmed_tokens:,}")
        print(f"- å‡å°‘: {original_tokens - trimmed_tokens:,} tokens ({(original_tokens - trimmed_tokens) / original_tokens * 100:.1f}%)")
        
        # åˆ†æä¸ºä»€ä¹ˆè¿˜æ˜¯è¶…é™
        model_limit = token_manager.get_model_limit("deepseek-chat")
        if trimmed_tokens > model_limit:
            print(f"\nâš ï¸ é—®é¢˜: å³ä½¿ä¿®å‰ªåä»ç„¶è¶…å‡ºæ¨¡å‹é™åˆ¶!")
            print(f"- æ¨¡å‹é™åˆ¶: {model_limit:,} tokens")
            print(f"- å®é™…éœ€è¦: {trimmed_tokens:,} tokens")
            print(f"- è¶…å‡º: {trimmed_tokens - model_limit:,} tokens")
            
            # åˆ†ææ¶ˆæ¯ç»„æˆ
            print("\nğŸ“Š æ¶ˆæ¯ç»„æˆåˆ†æ:")
            message_types = {}
            for msg in trimmed_messages:
                msg_type = type(msg).__name__
                if msg_type not in message_types:
                    message_types[msg_type] = {"count": 0, "tokens": 0}
                message_types[msg_type]["count"] += 1
                if isinstance(msg, SystemMessage):
                    msg_dict = {"role": "system", "content": msg.content}
                elif isinstance(msg, HumanMessage):
                    msg_dict = {"role": "user", "content": msg.content}
                elif isinstance(msg, AIMessage):
                    msg_dict = {"role": "assistant", "content": msg.content}
                message_types[msg_type]["tokens"] += counter.count_messages_tokens([msg_dict])
            
            for msg_type, stats in message_types.items():
                print(f"- {msg_type}: {stats['count']} æ¡, {stats['tokens']:,} tokens")
        
    except Exception as e:
        print(f"âŒ Token ç®¡ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # 4. å»ºè®®è§£å†³æ–¹æ¡ˆ
    print("\nğŸ’¡ å»ºè®®è§£å†³æ–¹æ¡ˆ:")
    print("1. å‡å°‘ researcher èŠ‚ç‚¹çš„ max_tokens é…ç½®")
    print("2. å¢åŠ æ›´æ¿€è¿›çš„ä¿®å‰ªç­–ç•¥")
    print("3. é™åˆ¶å·¥å…·è°ƒç”¨ç»“æœçš„é•¿åº¦")
    print("4. ä½¿ç”¨æ‘˜è¦è€Œä¸æ˜¯å®Œæ•´çš„æœç´¢ç»“æœ")
    print("5. è€ƒè™‘åˆ†é˜¶æ®µå¤„ç†ï¼Œé¿å…ç´¯ç§¯è¿‡å¤šä¸Šä¸‹æ–‡")

def check_actual_logs():
    """æ£€æŸ¥å®é™…çš„æ—¥å¿—æ–‡ä»¶"""
    print("\nğŸ“ æ£€æŸ¥å®é™…æ—¥å¿—:")
    log_dir = Path("logs/token_comparisons")
    if log_dir.exists():
        json_files = list(log_dir.glob("*.json"))
        print(f"æ‰¾åˆ° {len(json_files)} ä¸ªæ¯”è¾ƒæ–‡ä»¶")
        
        # æŸ¥æ‰¾æœ€æ–°çš„ researcher ç›¸å…³æ–‡ä»¶
        researcher_files = [f for f in json_files if "researcher" in f.name]
        if researcher_files:
            latest = max(researcher_files, key=lambda f: f.stat().st_mtime)
            print(f"\næœ€æ–°çš„ researcher æ¯”è¾ƒæ–‡ä»¶: {latest.name}")
            
            with open(latest, 'r') as f:
                data = json.load(f)
                print(f"- åŸå§‹æ¶ˆæ¯æ•°: {data.get('original_message_count', 'N/A')}")
                print(f"- åŸå§‹ tokens: {data.get('original_tokens', 'N/A'):,}")
                print(f"- ä¿®å‰ªåæ¶ˆæ¯æ•°: {data.get('trimmed_message_count', 'N/A')}")
                print(f"- ä¿®å‰ªå tokens: {data.get('trimmed_tokens', 'N/A'):,}")

if __name__ == "__main__":
    analyze_token_issue()
    check_actual_logs()